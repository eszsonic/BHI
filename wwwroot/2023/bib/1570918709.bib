@inproceedings{Wang2310:Intelligent,
AUTHOR    = {Changyi Wu and Dongmin Huang and Xiaoting Tao and Kun Qiao and Hongzhou Lu
and Wenjin Wang},
TITLE    = {Intelligent Stethoscope using Full {Self-Attention} Mechanism for Abnormal
Respiratory Sound Recognition},
BOOKTITLE    = {2023 IEEE EMBS International Conference on Biomedical and Health
Informatics (BHI) (IEEE BHI 2023)},
ADDRESS    = {Pittsburgh, USA},
PAGES    = {4},
DAYS    = {15},
MONTH    = {October},
YEAR    = {2023},
KEYWORDS    = {Stethoscope; respiratory sound; Transformer; signal segmentation; ICBHI
2017},
ABSTRACT    = {Machine learning automates the recognition of abnormal respiratory sounds
and pulmonary diseases for wireless stethoscopes. However, most
learning-based methods have unbalanced performance between low sensitivity
(SEN) and high specificity (SPE). Recently, the full self-attention
mechanism-based Transformer made significant progress in various medical
tasks, but its role in respiratory sound recognition still remains unknown.
It can extract the contextual information from segments with arbitrary
length in a signal, especially with long-range dependencies. This is
typically suitable for mining the pattern of temporally-continuous
pathological respiratory sounds, including stridor, wheezes, and rhonchi.
Thus in this paper, we explore the feasibility of using full self-attention
mechanism of Audio Spectrogram Transformer (AST) to improve the performance
of respiratory sound recognition, where FNN, CNN and AST are benchmarked on
the dataset of ICBHI 2017. In our proposed framework, the input samples are
generated by a new respiratory cycle-based segmentation in order to
preserve the consistency of input representation; a dual-input AST model is
designed to enhance the robustness to disturbances by extracting the
complementary information between the spectrograms and log Mel
spectrograms. Extensive experiments show that AST outperforms other methods
in the task of respiratory sound recognition. Moreover, the proposed
respiratory cycle-based segmentation considerably improves SEN by almost
10\%.},
}