@inproceedings{Kada2310:Providing,
AUTHOR    = {Adesh Kadambi and Jose Zariffa},
TITLE    = {Providing Hand Use Context for Outpatient Neurorehabilitation with
Egocentric Object Detection},
BOOKTITLE    = {2023 IEEE EMBS International Conference on Biomedical and Health
Informatics (BHI) (IEEE BHI 2023)},
ADDRESS    = {Pittsburgh, USA},
PAGES    = {4},
DAYS    = {15},
MONTH    = {October},
YEAR    = {2023},
KEYWORDS    = {egocentric video; object detection; spinal cord injury;
neurorehabilitation; wearable technology},
ABSTRACT    = {Recent advancements in wearable technology and machine learning have the
potential to enhance rehabilitation therapy, particularly in outpatient
settings. However, to effectively support therapy planning, such
technologies need to capture context-specific information about an
individual's activities of daily living (ADLs). In this study, we evaluated
the performance of two object detection models, Detic and UniDet, on
egocentric videos recorded by individuals with spinal cord injury (SCI).
Our evaluations revealed that UniDet, when evaluated on its original 700
classes, achieved a Mean Average Precision (mAP) of 0.0382 for all objects
and 0.0988 for active objects. When evaluated on a set of 27 consolidated
functional categories, UniDet's performance improved to an mAP of 0.1503
for all objects and 0.1910 for active objects. Detic demonstrated superior
performance with an mAP of 0.1772 for all objects and 0.2754 for active
objects when evaluated on the 27 functional categories. However, the ground
truth labelling strategy resulted in a large number of false positives,
suggesting that the model performance is likely higher. Despite challenges
posed by low-light conditions and motion blur, this study provides crucial
insights into the potential of object detection models in therapy planning,
facilitating the integration of wearable technology and machine learning in
outpatient rehabilitation and enabling more personalized and effective
therapeutic strategies.},
}