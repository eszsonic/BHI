@inproceedings{Mazu2310:Multimodal,
AUTHOR    = {Badhan Mazumder and Deepan Tripathy and Keith Yeates and Miriam Beauchamp
and William Craig and Quynh Doan and Stephen Freedman and Catherine Lebel
and Roger Zemek and Ashley Ware and Dong Hye Ye},
TITLE    = {Multimodal Deep Learning for Pediatric Mild Traumatic Brain Injury
Detection},
BOOKTITLE    = {2023 IEEE EMBS International Conference on Biomedical and Health
Informatics (BHI) (IEEE BHI 2023)},
ADDRESS    = {Pittsburgh, USA},
PAGES    = {4},
DAYS    = {15},
MONTH    = {October},
YEAR    = {2023},
KEYWORDS    = {Multimodal; Deep Learning; Explainable AI; Mild Traumatic Brain Injury},
ABSTRACT    = {Despite its prevalence, little is known about the pathophysiology of mild
traumatic brain injury (mTBI). This makes it difficult for clinicians to
accurately diagnose mTBI and predict outcomes in affected children, thereby
highlighting the urgent need to identify novel and efficacious biomarkers
of pediatric mTBI. To address this important knowledge gap, this study
introduced a multimodal MRI deep learning approach toward the
classification of mTBI as compared with mild orthopedic injury (OI) by
considering both structural MRI (sMRI) and diffusion tensor imaging (DTI).
Firstly, convolutional features were extracted by employing a pre-trained
DenseNet to capture the morphological features of both modalities. Next, by
employing Deep Canonical Correlation Analysis (DCCA), distinct features
obtained from the sMRI and DTI data were integrated into a multi-modal
embedding. The obtained DCCA fused compact multimodal features were then
fed to a random forest (RF) classifier that was used to classify mTBI
versus mild OI. Additionally, to visualize the intra-individually
heterogeneous brain regions that DenseNet most heavily relied upon for
making classification, Gradient-weighted Class Activation Mapping
(Grad-CAM) was applied to the DenseNet outcomes for both modalities.
According to the experimental outcomes on the clinical dataset, the
introduced multimodal deep learning strategy improved the classification
accuracy by 8.6\% (from 75.8\% to 84.4\%) and 7.8\% (from 76.6\% to 84.4\%)
when compared to the unimodal morphological features, as generated from
sMRI and DTI.},
}